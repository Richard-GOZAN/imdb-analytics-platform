# ğŸ¬ IMDB Analytics Platform

A comprehensive data platform built on IMDB datasets, featuring automated data ingestion, dbt transformations, and an LLM-powered chat interface for natural language queries.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![dbt](https://img.shields.io/badge/dbt-1.9+-orange.svg)](https://www.getdbt.com/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.39+-red.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#ï¸-architecture)
- [Features](#-features)
- [Tech Stack](#ï¸-tech-stack)
- [Getting Started](#-getting-started)
- [Project Structure](#-project-structure)
- [Usage](#-usage)
- [Deployment](#-deployment)
- [Data Model](#-data-model)
- [Development](#-development)
- [Acknowledgments](#-acknowledgments)
- [License](#license)

## ğŸ¯ Overview

This project demonstrates a complete modern data platform workflow:

1. **Data Ingestion**: Automated daily ingestion from IMDB datasets to BigQuery
2. **Data Transformation**: SQL-based transformations using dbt for analytical models
3. **LLM Interface**: Natural language query interface powered by OpenAI GPT-4o

The platform enables users to ask questions like:
- "What are the top 10 highest-rated movies?"
- "Show me Christopher Nolan's filmography"
- "Which actors worked with Martin Scorsese?"

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMDB Datasets                            â”‚
â”‚              (7 TSV files, updated daily)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Ingestion    â”‚
              â”‚   (Python)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   BigQuery     â”‚
              â”‚ Bronze Layer   â”‚
              â”‚  (7 tables)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  dbt Transform â”‚
              â”‚ Silver Layer   â”‚
              â”‚  (8 models)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                                â”‚
       â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit   â”‚              â”‚   Cron Job      â”‚
â”‚  + GPT-4o    â”‚              â”‚  (Daily 2 AM)   â”‚
â”‚ Chat Interfaceâ”‚              â”‚  Auto-ingestion â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### Data Ingestion
- âœ… Automated download from IMDB datasets (7 TSV files)
- âœ… Conversion to Parquet format for efficiency
- âœ… Load into BigQuery bronze layer
- âœ… Idempotent pipeline (safe to re-run)
- âœ… Scheduled daily execution via cron job

### Data Transformation (dbt)
- âœ… 5 staging models for data cleaning
- âœ… 3 marts models (movies, dim_actors, dim_directors)
- âœ… Partitioned and clustered tables for performance
- âœ… Comprehensive data quality tests
- âœ… Full documentation and lineage

### LLM Chat Interface
- âœ… Natural language to SQL conversion via GPT-4o
- âœ… Automatic SQL execution on BigQuery
- âœ… Interactive chat with conversation history
- âœ… Model selection (GPT-4o, GPT-4o-mini, GPT-4-turbo)
- âœ… Usage statistics tracking (tokens, questions, session time)
- âœ… CSV export functionality

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Cloud Platform** | Google Cloud Platform (GCP) |
| **Data Warehouse** | BigQuery |
| **Data Pipeline** | Python 3.11, Pandas, PyArrow |
| **Transformation** | dbt |
| **LLM** | OpenAI GPT-4o |
| **Frontend** | Streamlit |
| **Containerization** | Docker |
| **CI/CD** | GitHub Actions |
| **Package Management** | uv |
| **Code Quality** | Ruff (linter + formatter) |

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- Google Cloud Platform account with BigQuery API enabled
- OpenAI API key
- `uv` package manager ([installation](https://github.com/astral-sh/uv))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Richard-GOZAN/imdb-analytics-platform.git
   cd imdb-analytics-platform
   ```

2. **Install dependencies**
   ```bash
   uv sync
   ```

3. **Configure environment**
   ```bash
   cp .env.template .env
   # Edit .env with your credentials
   ```

4. **Run ingestion**
   ```bash
   uv run python ingestion/ingest.py
   ```

5. **Run dbt transformations**
   ```bash
   cd dbt/transform
   uv run dbt run
   ```

6. **Launch chat app**
   ```bash
   uv run streamlit run app/chat.py
   # Access: http://localhost:8501
   ```

## ğŸ“ Project Structure

```
imdb-analytics-platform/
â”œâ”€â”€ ingestion/              # Data ingestion pipeline
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ ingest.py          # Main script
â”‚   â””â”€â”€ utils.py           # Helper functions
â”œâ”€â”€ dbt/transform/         # dbt transformation project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/       # Staging models (5)
â”‚   â”‚   â””â”€â”€ marts/         # Marts models (3)
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â”œâ”€â”€ app/                   # LLM chat application
â”‚   â”œâ”€â”€ chat.py           # Streamlit interface
â”‚   â”œâ”€â”€ agent.py          # OpenAI agent
â”‚   â”œâ”€â”€ bigquery_tool.py  # BigQuery execution
â”‚   â””â”€â”€ stats.py          # Usage tracking
â”œâ”€â”€ docker/               # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile.app
â”‚   â””â”€â”€ Dockerfile.ingestion
â”œâ”€â”€ scripts/              # Automation scripts
â”‚   â”œâ”€â”€ run_ingestion.sh  # Pipeline wrapper
â”‚   â””â”€â”€ setup_cron.sh     # Cron installation
â”œâ”€â”€ .github/workflows/    # CI/CD
â”‚   â”œâ”€â”€ test.yml         # Tests
â”‚   â””â”€â”€ deploy-app.yml   # Deployment
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸ’¡ Usage

### Ingestion Pipeline

```bash
# Full ingestion
uv run python ingestion/ingest.py

# Force re-download
uv run python ingestion/ingest.py --force-download
```

**Datasets ingested:**
- `name.basics` - Person information
- `title.basics` - Movie information
- `title.ratings` - Ratings and votes
- `title.crew` - Director assignments
- `title.principals` - Principal cast/crew
- `title.akas` - Alternative titles
- `title.episode` - TV episode info

### dbt Transformations

```bash
cd dbt/transform

# Run all models
uv run dbt run

# Run tests
uv run dbt test

# Generate docs
uv run dbt docs generate && dbt docs serve
```

**Models:**
- **Staging** (5 models): Data cleaning and filtering
- **Marts** (3 models):
  - `movies` - Fact table (11.9K rows)
  - `dim_actors` - Actor dimension (30.7K actors)
  - `dim_directors` - Director dimension (3.6K directors)

### Chat Application

```bash
uv run streamlit run app/chat.py
```

**Example queries:**
- "Top 10 highest-rated movies"
- "Christopher Nolan's filmography"
- "Actors who worked with Scorsese"

## ğŸš¢ Deployment

### Local with Docker

```bash
# Build
docker compose build

# Run app
docker compose up app

# Run ingestion
docker compose run --rm ingestion
```

### Production (GCP VM)

```bash
# Setup cron job
./scripts/setup_cron.sh

# Runs daily at 2 AM automatically
```

### CI/CD

GitHub Actions workflows:
- **Lint**: Automatic linting on push
- **Deploy**: Manual deployment to VM via SSH

## ğŸ“Š Data Model

### Movies (Fact Table)
```sql
movie_id          STRING
title             STRING
release_year      INTEGER
average_rating    FLOAT64
num_votes         INTEGER
directors         ARRAY<STRUCT<id, name, birth_year>>
actors            ARRAY<STRUCT<id, name, characters, gender>>
```

### Dimensions
- `dim_directors` - Director details with filmography
- `dim_actors` - Actor details with career stats

## ğŸ§ª Development

### Code Quality

Pre-commit hooks automatically run:
- Code formatting (Ruff)
- Import sorting (Ruff)
- Style checks (Ruff)

```bash
# Run linting
uv run ruff check .

# Run formatting
uv run ruff format .
```


## ğŸ™ Acknowledgments

- [IMDB Datasets](https://developer.imdb.com/non-commercial-datasets/)
- [dbt Labs](https://www.getdbt.com/)
- [OpenAI](https://openai.com/)

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

---

â­ If you find this project useful, please star it!
